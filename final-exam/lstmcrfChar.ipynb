{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import visdom\n",
    "import sys\n",
    "import tqdm\n",
    "UNK = '<unk>'\n",
    "PAD = '<pad>'\n",
    "NULL = 'NULL'\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    # word, tag, character, orth, label\n",
    "    def __init__(self):\n",
    "        self.train_label_path = \"./data/train/train.txt\"\n",
    "        self.dev_label_path = \"./data/dev/dev.txt\"\n",
    "        self.test_path = \"./data/test/test.nolabels.txt\"\n",
    "        self.word_to_id = None\n",
    "        self.id_to_word = None\n",
    "        self.tag_to_id = None\n",
    "        self.id_to_tag = None\n",
    "        self.label_to_id = None\n",
    "        self.id_to_label = None\n",
    "        self.char_to_id = None\n",
    "        self.id_to_char = None\n",
    "        self.orth_to_id = None\n",
    "        self.id_to_orth = None\n",
    "        self.max_len = 52\n",
    "\n",
    "    def load_data(self,mode):\n",
    "        sentences, tags, labels = self.build_sentences(mode)\n",
    "        if mode == 'train':\n",
    "            self.build_vocab(sentences,tags,labels)\n",
    "        return sentences,labels\n",
    "\n",
    "    def build_vocab(self,sentences,tags,labels):\n",
    "        # build word-id char-id orth-id dictionary\n",
    "        counts = {}\n",
    "        char_to_id = {}\n",
    "        orth_to_id = {}\n",
    "        charidx = 0\n",
    "        orthidx = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word not in counts:counts[word]=1\n",
    "                else: counts[word]+=1\n",
    "                # orthographic\n",
    "                orthword = self.orthographic(word)\n",
    "                if orthword not in orth_to_id:\n",
    "                    orth_to_id[orthword] = orthidx\n",
    "                    orthidx += 1\n",
    "                # character\n",
    "                for char in word:\n",
    "                    if char not in char_to_id:\n",
    "                        char_to_id[char] = charidx\n",
    "                        charidx+=1\n",
    "        char_to_id[UNK] = charidx\n",
    "        id_to_char = {v:k for k,v in char_to_id.items()}\n",
    "        self.char_to_id = char_to_id\n",
    "        self.id_to_char = id_to_char\n",
    "        orth_to_id[UNK] = orthidx\n",
    "        id_to_orth = {v:k for k,v in orth_to_id.items()}\n",
    "        self.orth_to_id = orth_to_id\n",
    "        self.id_to_orth = id_to_orth\n",
    "        sorted_counts = sorted(counts.items(),key=lambda x:(-x[1],x[0]))\n",
    "        word_to_id = {}\n",
    "        idx = 0\n",
    "        for word,count in sorted_counts:\n",
    "            if word not in word_to_id:\n",
    "                word_to_id[word] = idx\n",
    "                idx += 1\n",
    "        word_to_id[UNK] = idx\n",
    "        id_to_word = {v:k for k,v in word_to_id.items()}\n",
    "        self.word_to_id = word_to_id\n",
    "        self.id_to_word = id_to_word\n",
    "\n",
    "        # build label-id dictionary\n",
    "        label_to_id={START_TAG:0}\n",
    "        idx=1\n",
    "        for sentence_label in labels:\n",
    "            for label in sentence_label:\n",
    "                if label not in label_to_id:\n",
    "                    label_to_id[label] = idx\n",
    "                    idx+=1\n",
    "        label_to_id[STOP_TAG]=idx\n",
    "        id_to_label = {v:k for k,v in label_to_id.items()}\n",
    "        self.label_to_id = label_to_id\n",
    "        self.id_to_label = id_to_label\n",
    "\n",
    "        # build tag-id dictionary\n",
    "        tag_to_id = {NULL:0}\n",
    "        idx=1\n",
    "        for sentence_tag in tags:\n",
    "            for tag in sentence_tag:\n",
    "                if tag not in tag_to_id:\n",
    "                    tag_to_id[tag] = idx\n",
    "                    idx += 1\n",
    "        id_to_tag = {v:k for k,v in tag_to_id.items()}\n",
    "        self.tag_to_id = tag_to_id\n",
    "        self.id_to_tag = id_to_tag\n",
    "\n",
    "    def orthographic(self, word):\n",
    "        ortho_word = ''\n",
    "        for char in word:\n",
    "            if char.isupper():\n",
    "                ortho_word += 'C'\n",
    "            elif char.islower():\n",
    "                ortho_word += 'c'\n",
    "            elif char.isdigit():\n",
    "                ortho_word += 'n'\n",
    "            else:\n",
    "                ortho_word += 'p'\n",
    "        return ortho_word\n",
    "\n",
    "    def build_sentences(self,mode):\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        tags = []\n",
    "        if mode==\"test\":\n",
    "            with open(self.test_path,encoding='utf-8') as f:\n",
    "                sentence=[]\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        sentences.append(sentence)\n",
    "                        tags.append([pair[1] for pair in nltk.pos_tag(sentence)])\n",
    "                        sentence = []\n",
    "                        continue\n",
    "                    sentence.append(line.lower())\n",
    "        else:\n",
    "            if mode==\"train\": file = open(self.train_label_path,encoding='utf-8')\n",
    "            else: file = open(self.dev_label_path,encoding='utf-8')\n",
    "            sentence=[]\n",
    "            label=[]\n",
    "            for line in file:\n",
    "                line = line.split()\n",
    "                if not line:\n",
    "                    sentences.append(sentence)\n",
    "                    tags.append([pair[1] for pair in nltk.pos_tag(sentence)])\n",
    "                    labels.append(label)\n",
    "                    sentence=[]\n",
    "                    label=[]\n",
    "                    continue\n",
    "                word,wordlabel = line\n",
    "                sentence.append(word.lower())\n",
    "                label.append(wordlabel)\n",
    "            file.close()\n",
    "        return sentences,tags,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(sentences,labels, word_to_id, char_to_id, tag_to_id, lower=True):\n",
    "    def f(x): return x.lower() if lower else x\n",
    "    data = []\n",
    "    for i in range(len(sentences)):\n",
    "        s = sentences[i]\n",
    "        str_words = [w for w in s]\n",
    "        words = [word_to_id[f(w) if f(w) in word_to_id else UNK]\n",
    "                 for w in str_words]\n",
    "        # Skip characters that are not in the training set\n",
    "        chars = [[char_to_id[c if c in char_to_id else UNK] for c in w] for w in str_words]\n",
    "        caps = [cap_feature(w) for w in str_words]\n",
    "        if len(labels)!=0:tags = [tag_to_id[w] for w in labels[i]]\n",
    "        else: tags=[]\n",
    "        data.append({\n",
    "            'str_words': str_words,\n",
    "            'words': words,\n",
    "            'chars': chars,\n",
    "            'caps': caps,\n",
    "            'tags': tags,\n",
    "        })\n",
    "    return data\n",
    "def cap_feature(s):\n",
    "    \"\"\"\n",
    "    Capitalization feature:\n",
    "    0 = low caps\n",
    "    1 = all caps\n",
    "    2 = first letter caps\n",
    "    3 = one capital (not first letter)\n",
    "    \"\"\"\n",
    "    if s.lower() == s:\n",
    "        return 0\n",
    "    elif s.upper() == s:\n",
    "        return 1\n",
    "    elif s[0].upper() == s[0]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "def init_embedding(input_embedding):\n",
    "    \"\"\"\n",
    "    Initialize embedding\n",
    "    \"\"\"\n",
    "    bias = np.sqrt(3.0 / input_embedding.size(1))\n",
    "    nn.init.uniform(input_embedding, -bias, bias)\n",
    "\n",
    "def init_linear(input_linear):\n",
    "    \"\"\"\n",
    "    Initialize linear transformation\n",
    "    \"\"\"\n",
    "    bias = np.sqrt(6.0 / (input_linear.weight.size(0) + input_linear.weight.size(1)))\n",
    "    nn.init.uniform(input_linear.weight, -bias, bias)\n",
    "    if input_linear.bias is not None:\n",
    "        input_linear.bias.data.zero_()\n",
    "\n",
    "\n",
    "def init_lstm(input_lstm):\n",
    "    \"\"\"\n",
    "    Initialize lstm\n",
    "    \"\"\"\n",
    "    for ind in range(0, input_lstm.num_layers):\n",
    "        weight = eval('input_lstm.weight_ih_l' + str(ind))\n",
    "        bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "        nn.init.uniform(weight, -bias, bias)\n",
    "        weight = eval('input_lstm.weight_hh_l' + str(ind))\n",
    "        bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "        nn.init.uniform(weight, -bias, bias)\n",
    "    if input_lstm.bidirectional:\n",
    "        for ind in range(0, input_lstm.num_layers):\n",
    "            weight = eval('input_lstm.weight_ih_l' + str(ind) + '_reverse')\n",
    "            bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "            nn.init.uniform(weight, -bias, bias)\n",
    "            weight = eval('input_lstm.weight_hh_l' + str(ind) + '_reverse')\n",
    "            bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "            nn.init.uniform(weight, -bias, bias)\n",
    "\n",
    "    if input_lstm.bias:\n",
    "        for ind in range(0, input_lstm.num_layers):\n",
    "            weight = eval('input_lstm.bias_ih_l' + str(ind))\n",
    "            weight.data.zero_()\n",
    "            weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "            weight = eval('input_lstm.bias_hh_l' + str(ind))\n",
    "            weight.data.zero_()\n",
    "            weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "        if input_lstm.bidirectional:\n",
    "            for ind in range(0, input_lstm.num_layers):\n",
    "                weight = eval('input_lstm.bias_ih_l' + str(ind) + '_reverse')\n",
    "                weight.data.zero_()\n",
    "                weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "                weight = eval('input_lstm.bias_hh_l' + str(ind) + '_reverse')\n",
    "                weight.data.zero_()\n",
    "                weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "                \n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, char_lstm_dim=25,\n",
    "                 char_to_ix=None, pre_word_embeds=None, char_embedding_dim=25, use_gpu=False,\n",
    "                 n_cap=None, cap_embedding_dim=None, use_crf=True, char_mode='CNN'):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.n_cap = n_cap\n",
    "        self.cap_embedding_dim = cap_embedding_dim\n",
    "        self.use_crf = use_crf\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.out_channels = char_lstm_dim\n",
    "        self.char_mode = char_mode\n",
    "\n",
    "        print('char_mode: %s, out_channels: %d, hidden_dim: %d, ' % (char_mode, char_lstm_dim, hidden_dim))\n",
    "\n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            self.cap_embeds = nn.Embedding(self.n_cap, self.cap_embedding_dim)\n",
    "            init_embedding(self.cap_embeds.weight)\n",
    "\n",
    "        if char_embedding_dim is not None:\n",
    "            self.char_lstm_dim = char_lstm_dim\n",
    "            self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
    "            init_embedding(self.char_embeds.weight)\n",
    "            if self.char_mode == 'LSTM':\n",
    "                self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
    "                init_lstm(self.char_lstm)\n",
    "            if self.char_mode == 'CNN':\n",
    "                self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pre_word_embeds is not None:\n",
    "            self.pre_word_embeds = True\n",
    "            self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
    "        else:\n",
    "            self.pre_word_embeds = False\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            if self.char_mode == 'LSTM':\n",
    "                self.lstm = nn.LSTM(embedding_dim+char_lstm_dim*2+cap_embedding_dim, hidden_dim, bidirectional=True)\n",
    "            if self.char_mode == 'CNN':\n",
    "                self.lstm = nn.LSTM(embedding_dim+self.out_channels+cap_embedding_dim, hidden_dim, bidirectional=True)\n",
    "        else:\n",
    "            if self.char_mode == 'LSTM':\n",
    "                self.lstm = nn.LSTM(embedding_dim+char_lstm_dim*2, hidden_dim, bidirectional=True)\n",
    "            if self.char_mode == 'CNN':\n",
    "                self.lstm = nn.LSTM(embedding_dim+self.out_channels, hidden_dim, bidirectional=True)\n",
    "        init_lstm(self.lstm)\n",
    "        self.hw_trans = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.hw_gate = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.h2_h1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
    "        init_linear(self.h2_h1)\n",
    "        init_linear(self.hidden2tag)\n",
    "        init_linear(self.hw_gate)\n",
    "        init_linear(self.hw_trans)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.transitions = nn.Parameter(\n",
    "                torch.zeros(self.tagset_size, self.tagset_size))\n",
    "            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "            self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # tags is ground_truth, a list of ints, length is len(sentence)\n",
    "        # feats is a 2D tensor, len(sentence) * tagset_size\n",
    "        r = torch.LongTensor(range(feats.size()[0]))\n",
    "        if self.use_gpu:\n",
    "            r = r.cuda()\n",
    "            pad_start_tags = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
    "            pad_stop_tags = torch.cat([tags, torch.cuda.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
    "        else:\n",
    "            pad_start_tags = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
    "            pad_stop_tags = torch.cat([tags, torch.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
    "\n",
    "        score = torch.sum(self.transitions[pad_stop_tags, pad_start_tags]) + torch.sum(feats[r, tags])\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _get_lstm_features(self, sentence, chars2, caps, chars2_length, d):\n",
    "\n",
    "        if self.char_mode == 'LSTM':\n",
    "            # self.char_lstm_hidden = self.init_lstm_hidden(dim=self.char_lstm_dim, bidirection=True, batchsize=chars2.size(0))\n",
    "            chars_embeds = self.char_embeds(chars2).transpose(0, 1)\n",
    "            packed = torch.nn.utils.rnn.pack_padded_sequence(chars_embeds, chars2_length)\n",
    "            lstm_out, _ = self.char_lstm(packed)\n",
    "            outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
    "            outputs = outputs.transpose(0, 1)\n",
    "            chars_embeds_temp = Variable(torch.FloatTensor(torch.zeros((outputs.size(0), outputs.size(2)))))\n",
    "            if self.use_gpu:\n",
    "                chars_embeds_temp = chars_embeds_temp.cuda()\n",
    "            for i, index in enumerate(output_lengths):\n",
    "                chars_embeds_temp[i] = torch.cat((outputs[i, index-1, :self.char_lstm_dim], outputs[i, 0, self.char_lstm_dim:]))\n",
    "            chars_embeds = chars_embeds_temp.clone()\n",
    "            for i in range(chars_embeds.size(0)):\n",
    "                chars_embeds[d[i]] = chars_embeds_temp[i]\n",
    "\n",
    "        if self.char_mode == 'CNN':\n",
    "            chars_embeds = self.char_embeds(chars2).unsqueeze(1)\n",
    "            chars_cnn_out3 = self.char_cnn3(chars_embeds)\n",
    "            chars_embeds = nn.functional.max_pool2d(chars_cnn_out3,\n",
    "                                                 kernel_size=(chars_cnn_out3.size(2), 1)).view(chars_cnn_out3.size(0), self.out_channels)\n",
    "\n",
    "\n",
    "        embeds = self.word_embeds(sentence)\n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            cap_embedding = self.cap_embeds(caps)\n",
    "\n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            embeds = torch.cat((embeds, chars_embeds, cap_embedding), 1)\n",
    "        else:\n",
    "            embeds = torch.cat((embeds, chars_embeds), 1)\n",
    "\n",
    "        embeds = embeds.unsqueeze(1)\n",
    "        embeds = self.dropout(embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim*2)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # calculate in log domain\n",
    "        # feats is len(sentence) * tagset_size\n",
    "        # initialize alpha with a Tensor with values all equal to -10000.\n",
    "        init_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "        forward_var = autograd.Variable(init_alphas)\n",
    "        if self.use_gpu:\n",
    "            forward_var = forward_var.cuda()\n",
    "        for feat in feats:\n",
    "            emit_score = feat.view(-1, 1)\n",
    "            tag_var = forward_var + self.transitions + emit_score\n",
    "            max_tag_var, _ = torch.max(tag_var, dim=1)\n",
    "            tag_var = tag_var - max_tag_var.view(-1, 1)\n",
    "            forward_var = max_tag_var + torch.log(torch.sum(torch.exp(tag_var), dim=1)).view(1, -1) # ).view(1, -1)\n",
    "        terminal_var = (forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]).view(1, -1)\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        # Z(x)\n",
    "        return alpha\n",
    "\n",
    "    def viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "        # analogous to forward\n",
    "        init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "        forward_var = Variable(init_vvars)\n",
    "        if self.use_gpu:\n",
    "            forward_var = forward_var.cuda()\n",
    "        for feat in feats:\n",
    "            next_tag_var = forward_var.view(1, -1).expand(self.tagset_size, self.tagset_size) + self.transitions\n",
    "            _, bptrs_t = torch.max(next_tag_var, dim=1)\n",
    "            bptrs_t = bptrs_t.squeeze().data.cpu().numpy()\n",
    "            next_tag_var = next_tag_var.data.cpu().numpy()\n",
    "            viterbivars_t = next_tag_var[range(len(bptrs_t)), bptrs_t]\n",
    "            viterbivars_t = Variable(torch.FloatTensor(viterbivars_t))\n",
    "            if self.use_gpu:\n",
    "                viterbivars_t = viterbivars_t.cuda()\n",
    "            forward_var = viterbivars_t + feat\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        terminal_var.data[self.tag_to_ix[STOP_TAG]] = -10000.\n",
    "        terminal_var.data[self.tag_to_ix[START_TAG]] = -10000.\n",
    "        best_tag_id = argmax(terminal_var.unsqueeze(0))\n",
    "        path_score = terminal_var[best_tag_id]\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags, chars2, caps, chars2_length, d):\n",
    "        # sentence, tags is a list of ints\n",
    "        # features is a 2D tensor, len(sentence) * self.tagset_size\n",
    "        feats = self._get_lstm_features(sentence, chars2, caps, chars2_length, d)\n",
    "\n",
    "        if self.use_crf:\n",
    "            forward_score = self._forward_alg(feats)\n",
    "            gold_score = self._score_sentence(feats, tags)\n",
    "            return forward_score - gold_score\n",
    "        else:\n",
    "            tags = Variable(tags)\n",
    "            scores = nn.functional.cross_entropy(feats, tags)\n",
    "            return scores\n",
    "\n",
    "\n",
    "    def forward(self, sentence, chars, caps, chars2_length, d):\n",
    "        feats = self._get_lstm_features(sentence, chars, caps, chars2_length, d)\n",
    "        # viterbi to get tag_seq\n",
    "        if self.use_crf:\n",
    "            score, tag_seq = self.viterbi_decode(feats)\n",
    "        else:\n",
    "            score, tag_seq = torch.max(feats, 1)\n",
    "            tag_seq = list(tag_seq.cpu().data)\n",
    "\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data from file\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Data from file\")\n",
    "loader = Loader()\n",
    "train,train_labels = loader.load_data('train')\n",
    "dev,dev_labels = loader.load_data('dev')\n",
    "test,test_labels = loader.load_data('test')\n",
    "train_data = prepare_dataset(train,train_labels, loader.word_to_id, loader.char_to_id, loader.label_to_id)\n",
    "dev_data = prepare_dataset(dev,dev_labels, loader.word_to_id, loader.char_to_id, loader.label_to_id)\n",
    "test_data = prepare_dataset(test,test_labels, loader.word_to_id, loader.char_to_id, loader.label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 pretrained embeddings.\n"
     ]
    }
   ],
   "source": [
    "parameters = OrderedDict()\n",
    "parameters['lower'] = 1\n",
    "parameters['zeros'] = 1\n",
    "parameters['char_mode'] = 'LSTM'\n",
    "\n",
    "all_word_embeds = {}\n",
    "file = open('data/glove.6B/glove.6B.100d.txt',encoding = 'utf-8')\n",
    "i=0\n",
    "for line in file:\n",
    "    s = line.strip().split()\n",
    "    if len(s) == 100 + 1:\n",
    "        all_word_embeds[s[0]] = np.array([float(i) for i in s[1:]])\n",
    "    i+=1\n",
    "file.close()\n",
    "word_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (len(loader.word_to_id), 100))\n",
    "\n",
    "for w in loader.word_to_id:\n",
    "    if w in all_word_embeds:\n",
    "        word_embeds[loader.word_to_id[w]] = all_word_embeds[w]\n",
    "    elif w.lower() in all_word_embeds:\n",
    "        word_embeds[loader.word_to_id[w]] = all_word_embeds[w.lower()]\n",
    "\n",
    "print('Loaded %i pretrained embeddings.' % len(all_word_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_mode: LSTM, out_channels: 25, hidden_dim: 200, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (char_embeds): Embedding(67, 25)\n",
       "  (char_lstm): LSTM(25, 25, bidirectional=True)\n",
       "  (word_embeds): Embedding(9069, 100)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (lstm): LSTM(150, 200, bidirectional=True)\n",
       "  (hw_trans): Linear(in_features=25, out_features=25, bias=True)\n",
       "  (hw_gate): Linear(in_features=25, out_features=25, bias=True)\n",
       "  (h2_h1): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (hidden2tag): Linear(in_features=400, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_CRF(vocab_size=len(loader.word_to_id),\n",
    "                   tag_to_ix=loader.label_to_id,\n",
    "                   embedding_dim=100,\n",
    "                   hidden_dim=200,\n",
    "                   char_to_ix=loader.char_to_id,\n",
    "                   pre_word_embeds=word_embeds,\n",
    "                   use_crf=1,\n",
    "                   char_mode='LSTM',\n",
    "                   n_cap=4,\n",
    "                   cap_embedding_dim=10)\n",
    "model.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "2394it [02:50, 14.05it/s]\n",
      "2394it [03:38, 10.96it/s]\n",
      "2394it [03:56, 10.12it/s]\n",
      "2394it [03:44, 10.68it/s]\n",
      "13it [00:01, 10.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-12e89c6a8b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mneg_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars2_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars2_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-2db5815df378>\u001b[0m in \u001b[0;36mneg_log_likelihood\u001b[0;34m(self, sentence, tags, chars2, caps, chars2_length, d)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# sentence, tags is a list of ints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# features is a 2D tensor, len(sentence) * self.tagset_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lstm_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars2_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_crf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-2db5815df378>\u001b[0m in \u001b[0;36m_get_lstm_features\u001b[0;34m(self, sentence, chars2, caps, chars2_length, d)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.015\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    for i, index in tqdm.tqdm(enumerate(np.random.permutation(len(train_data)))):\n",
    "        count += 1\n",
    "        data = train_data[index]\n",
    "        model.zero_grad()\n",
    "\n",
    "        sentence_in = data['words']\n",
    "        sentence_in = Variable(torch.LongTensor(sentence_in))\n",
    "        tags = data['tags']\n",
    "        chars2 = data['chars']\n",
    "\n",
    "        if parameters['char_mode'] == 'LSTM':\n",
    "            chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
    "            d = {}\n",
    "            for i, ci in enumerate(chars2):\n",
    "                for j, cj in enumerate(chars2_sorted):\n",
    "                    if ci == cj and not j in d and not i in d.values():\n",
    "                        d[j] = i\n",
    "                        continue\n",
    "            chars2_length = [len(c) for c in chars2_sorted]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2_sorted):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "        \n",
    "        targets = torch.LongTensor(tags)\n",
    "        caps = Variable(torch.LongTensor(data['caps']))\n",
    "        \n",
    "        neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets, chars2_mask, caps, chars2_length, d)\n",
    "        neg_log_likelihood.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 5.0)\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29198682766191003 0.6927083333333334 0.18497913769123783\n"
     ]
    }
   ],
   "source": [
    "def evaluating(model, datas):\n",
    "    prediction = []\n",
    "    y=[]\n",
    "    for data in datas:\n",
    "        ground_truth_id = data['tags']\n",
    "        words = data['str_words']\n",
    "        chars2 = data['chars']\n",
    "        caps = data['caps']\n",
    "\n",
    "        if parameters['char_mode'] == 'LSTM':\n",
    "            chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
    "            d = {}\n",
    "            for i, ci in enumerate(chars2):\n",
    "                for j, cj in enumerate(chars2_sorted):\n",
    "                    if ci == cj and not j in d and not i in d.values():\n",
    "                        d[j] = i\n",
    "                        continue\n",
    "            chars2_length = [len(c) for c in chars2_sorted]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2_sorted):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "\n",
    "        dwords = Variable(torch.LongTensor(data['words']))\n",
    "        dcaps = Variable(torch.LongTensor(caps))\n",
    "        val, out = model(dwords, chars2_mask, dcaps, chars2_length, d)\n",
    "        predicted_id = out\n",
    "        prediction.append(out)\n",
    "        y.append(ground_truth_id)\n",
    "    return prediction,y\n",
    "    \n",
    "def calculatef1(y,p,id_to_class):\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    for y_seq,p_seq in zip(y,p):\n",
    "        for y_id,p_id in zip(y_seq,p_seq):\n",
    "            y_ = id_to_class[y_id]\n",
    "            p_ = id_to_class[p_id]\n",
    "            if y_ != 'O':\n",
    "                if p_ == y_:\n",
    "                    true_pos += 1\n",
    "                elif p_ == 'O':\n",
    "                    false_neg += 1\n",
    "            elif p_ != y_:\n",
    "                false_pos += 1\n",
    "    prec = true_pos / (true_pos + false_pos) if true_pos + false_pos != 0 else 0\n",
    "    recall = true_pos / (true_pos + false_neg) if true_pos + false_neg != 0 else 0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec + recall != 0 else 0\n",
    "    return f1, prec, recall\n",
    "\n",
    "\n",
    "prediction,y = evaluating(model, dev_data)\n",
    "f1, prec, recall = calculatef1(y,prediction,loader.id_to_label)\n",
    "print(f1, prec, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = []\n",
    "for data in test_data:\n",
    "    ground_truth_id = data['tags']\n",
    "    words = data['str_words']\n",
    "    chars2 = data['chars']\n",
    "    caps = data['caps']\n",
    "\n",
    "    if parameters['char_mode'] == 'LSTM':\n",
    "        chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
    "        d = {}\n",
    "        for i, ci in enumerate(chars2):\n",
    "            for j, cj in enumerate(chars2_sorted):\n",
    "                if ci == cj and not j in d and not i in d.values():\n",
    "                    d[j] = i\n",
    "                    continue\n",
    "        chars2_length = [len(c) for c in chars2_sorted]\n",
    "        char_maxl = max(chars2_length)\n",
    "        chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
    "        for i, c in enumerate(chars2_sorted):\n",
    "            chars2_mask[i, :chars2_length[i]] = c\n",
    "        chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "    dwords = Variable(torch.LongTensor(data['words']))\n",
    "    dcaps = Variable(torch.LongTensor(caps))\n",
    "    val, out = model(dwords, chars2_mask, dcaps, chars2_length, d)\n",
    "    test_predict.append(out)\n",
    "\n",
    "file = open(\"test2.out\",'w',encoding='utf-8')\n",
    "for i in test_predict:\n",
    "    for j in i:\n",
    "        file.write(loader.id_to_label[j])\n",
    "        file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
